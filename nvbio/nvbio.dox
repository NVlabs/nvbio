/*
 * nvbio
 * Copyright (c) 2011-2014, NVIDIA CORPORATION. All rights reserved.
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *    * Redistributions of source code must retain the above copyright
 *      notice, this list of conditions and the following disclaimer.
 *    * Redistributions in binary form must reproduce the above copyright
 *      notice, this list of conditions and the following disclaimer in the
 *      documentation and/or other materials provided with the distribution.
 *    * Neither the name of the NVIDIA CORPORATION nor the
 *      names of its contributors may be used to endorse or promote products
 *      derived from this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

///\page nvbio_page NVBIO
///
///\htmlonly
/// <img src="nvidia_cubes.png" style="position:relative; bottom:-10px; border:0px;"/>
///\endhtmlonly
///
///\par
///\n
/// <b>NVBIO</b> is a library of reusable components designed to accelerate bioinformatics applications
/// using <i>CUDA</i>. Though it is specifically designed to unleash the power of <i>NVIDIA</i> <b>GPU</b>s,
/// most of its components are completely cross-platform and can be used both from host C++ and device
/// CUDA code.
///
/// \section IntroductionSection Introduction
///
/// - \subpage generic_programming_page
/// - \subpage host_device_page
/// - \subpage hello_dna_page
/// - \subpage hello_dna_2_page
///
/// \section ModulesSection Modules
///\par
/// NVBIO includes the following modules:
///
/// - \subpage basic_page
/// - \subpage strings_page
/// - \subpage alignment_page
/// - \subpage fmindex_page
/// - \subpage qgram_page
/// - \subpage sufsort_page
/// - \subpage tries_page
/// - \subpage io_page
/// - \subpage fasta_page
/// - \subpage fastq_page
///
/// \section PerformanceSection Performance
///\par
/// NVBIO is designed for performance. Here's a couple benchmarks showing the
/// superior speed of its FM-index search, DP alignment and BWT construction
/// algorithms.
///
/// <img src="benchmark-fm-index-speedup.png" style="position:relative; bottom:-10px; border:0px;" width="48%" height="48%"/>
///\n
/// <img src="benchmark-sw.png" style="position:relative; bottom:-10px; border:0px;" width="48%" height="48%"/>
///\n
/// <img src="benchmark-bwt.png" style="position:relative; bottom:-10px; border:0px;" width="48%" height="48%"/>
///
/// \section DependenciesSection Dependencies
///\par
/// NVBIO depends on the following external libraries:
///
/// - <a href="http://nvlabs.github.io/cub/">CUB</a>
/// - <a href="https://sites.google.com/site/yuta256/">SAIS</a>
/// - <a href="http://www.zlib.net/">zlib</a>
/// - <a href="http://www.barrgroup.com/Embedded-Systems/How-To/CRC-Calculation-C-Code">crc</a>
/// - a modification of Nathaniel McClatchey's <a href="https://github.com/nmcclatchey/Priority-Deque/">priority_deque</a>
///
/// \section Licensing
///\par
/// NVBIO has been developed by <a href="www.nvidia.com">NVIDIA Corporation</a> and is licensed under BSD.
///
/// \section Contributors
///\par
/// The main contributors of NVBIO are <a href="jpantaleoni@nvidia.com">Jacopo Pantaleoni</a> and <a href="nsubtil@nvidia.com">Nuno Subtil</a>.
///
///\htmlonly
/// <a href="http://research.nvidia.com"><img src="cuda_small.png" style="position:relative; bottom:-10px; border:0px;"/></a>
/// &nbsp;&nbsp;
///\endhtmlonly

/// \page host_device_page Host & Device
///\par
/// The user of NVBIO needs to familiarize with the fact that on a GPU equipped system
/// there is both a <i>host</i>, controlled by a <i>CPU</i>, and one or multiple <i>GPU</i> <i>devices</i>,
/// with distinct memory spaces.
/// Hence, there can be several types of functions and data-structures:
///\par
/// - single-threaded functions that can be called by a host thread
/// - single-threaded functions that can be called by a device thread
/// - single-threaded functions that can be called both on the host and the device
/// - parallel functions that can be called by a host thread, and spawn one or more sets of host threads
/// - parallel functions that can be called by a host thread, but spawn one or more sets of device threads
///\par
/// - data-structures that encapsulate host data and are meant to be used on the host
///   (e.g. a resizable host vector, nvbio::vector<host_tag,T>)
/// - data-structures that encapsulate device data but are meant to be used on the host
///   (e.g. a resizable device vector, nvbio::vector<device_tag,T>)
/// - data-structures that encapsulate device data and are meant to be used on the device
///\par
/// Unified Virtual Memory (coming with the NVIDIA Maxwell generation) will eventually allow
/// to use any data-structure anywhere, but for now we have to cope with the distinct memory
/// spaces.
///
/// \section PlainViewsSection Plain Views
///\par
/// The fact that some data structures contain device data but can only be used from the host,
/// coupled with the fact that at the moment CUDA does not allow to pass references
/// as device kernel arguments and requires to pass PODs in, lends naturally to the definition of
/// <i>plain views</i>: in NVBIO's speech, a plain view of an object is essentially a <i>shallow reference</i>
/// to an object's data encapsulated in a POD data structure that can be passed as kernel parameters.
///\par
/// NVBIO defines the generic function plain_view() to obtain the plain view of a given object.
/// Analogously it defines the meta function plain_view_subtype<T>::type to get the type of the
/// plain view of any given type T (where defined).
/// Moreover, as a convention NVBIO's data structures T define the subtype T::plain_view_type and
/// T::const_plain_view_type to identify their plain view types.
///\par
/// As an example consider the following situation, where on the host you have created a large device vector
/// you want to be filled by a device kernel.
/// Ideally, you'd want to simply pass a reference to the vector to your kernel, as in:
///\code
/// __global__ void my_kernel(                   // the CUDA kernel
///     nvbio::vector<device_tag,uint32>& vec)   // ideally, receive a reference: doesn't work without UVM!
/// {
///     const uint32 tid = threadIdx.x + blockIdx.x * blockDim.x; // compute a linear thread id
///     if (tid < vec.size())
///         vec[tid] = tid * 10;
/// }
///
/// int main()
/// {
///     nvbio::vector<device_tag,uint32> vec( 1000000 );
///
///     const uint32 blockdim = 128;
///     const uint32 n_blocks = util::divide_ri( vec.size(), blockdim ); 
///     my_kernel<<<n_blocks,blockdim>>>( vec );
/// }
///\endcode
///\par
/// However, this won't be possible in CUDA until UVM is finally available. With NVBIO, you'd do this instead:
///\code
/// __global__ void my_kernel(                   // the CUDA kernel
///     nvbio::vector_view<uint32> vec)          // NVBIO's surrogate of a reference
/// {
///     const uint32 tid = threadIdx.x + blockIdx.x * blockDim.x; // compute a linear thread id
///     if (tid < vec.size())
///         vec[tid] = tid * 10;
/// }
///
/// int main()
/// {
///     nvbio::vector<device_tag,uint32> vec( 1000000 );
///
///     const uint32 blockdim = 128;
///     const uint32 n_blocks = util::divide_ri( vec.size(), blockdim );
///     my_kernel<<<n_blocks,blockdim>>>( nvbio::plain_view( vec ) );
/// }
///\endcode
///\par
/// This basic pattern can be applied to all of NVBIO's data structures that are meant to be setup from the
/// host and accessed from the device.
///
/// Next: \subpage hello_dna_page

/// \page generic_programming_page Generic Programming
///\par
/// Most of NVBIO's functions and data structures are <em>C++ templates</em>
/// providing the flexibility and compile-time code generation needed
/// to accomodate the exponential amount of type combinations possible in typical
/// bioinformatics applications.
///\par
/// Just as an example, consider the problem of string alignment: one user might
/// want to use <em>Smith-Waterman</em> to perform <em>local</em> alignment between
/// two <em>ASCII</em> strings.
/// Another, might want to use <em>Edit-Distance</em> to align two <em>4-bit encoded</em>
/// strings  <em>semi-globally</em>.
/// Yet another might want to perform <em>banded</em> alignment using <em>Gotoh</em>'s
/// affine gap penalties, this time <em>globally</em> between an ASCII pattern and a 2-bit text.\n
/// Now consider the cross product of all the possible combinations:
/// <table>
/// <tr><td><b>Aligner</b></td><td>	<b>Alignment Type</b>	</td><td><b>DP Algorithm</b></td><td><b>Pattern Type</b></td><td><b>Text Type</b></td></tr>
/// <tr><td>Edit-Distance</td>		<td>Global</td>			<td>Full Matrix</td>	<td>ASCII</td>	<td>ASCII</td></tr>
/// <tr><td>Smith-Waterman</td>		<td>Semi-Global			</td><td>Banded</td>	<td>2-bit</td>	<td>2-bit</td></tr>
/// <tr><td>Gotoh</td>				<td>Local</td>			<td></td>				<td>4-bit</td>  <td>4-bit</td></tr>
/// </table>
/// Hard-coding them would result in <b>3 x 3 x 2 x 3 x 3 = 54</b> <em>almost equivalent <b>code paths!</b></em>\n
///\par
/// <b><em>Templates</em></b> instead allow:
///  - to express all these alignment problems elegantly using a <b><em>single interface</em></b>;
///  - while at the same time <b><em>not imposing any constraints</em></b> on the user's possibilities
///    who might for example easily experiment switching from ASCII to 2-bit encodings
///    or perhaps yet another custom representation of his choice;
///  - and to <b><em>optimize</em></b> the generated code at <em>compile-time</em>, specializing behaviour
///    for an important subset of the exponentially (or even infinitely) sized cross product
///    of all possible combinations.
///\par
/// And obviously, the same story goes for FM-indices, Bloom filters, and so on and so on...
///
/// Next: \subpage host_device_page

/// \page hello_dna_page Hello DNA!
///\par
/// This page will teach you to familiarize with some of NVBIO's basic containers and concepts,
/// showing you how to instantiate a \ref packed_streams_page "PackedVector" to store some DNA string.
/// Packed vectors are useful to represent streams of symbols using a few bits per symbol. For a DNA alphabet,
/// we'll only need 2-bits:
///
///\code
/// #include <nvbio/basic/packed_vector.h>
/// #include <nvbio/basic/dna.h>
///
/// void main()
/// {
///     // our hello world ASCII string
///     const char dna_string[] = "ACGTTGCA";
///     const uint32 len = uint32( strlen( dna_string ) );
///
///     // our DNA alphabet size
///     const uint32 ALPHABET_SIZE = 2u;
///
///     // instantiate a packed host vector
///     nvbio::PackedVector<host_tag,ALPHABET_SIZE> h_dna( len );
///
///     // and fill it in with the contents of our original string, converted
///     // to a 2-bit DNA alphabet (i.e. A = 0, C = 1, G = 2, T = 3)
///     nvbio::string_to_dna(
///         dna_string,               // the input ASCII string
///         h_dna.begin() );          // the output iterator
///
///     // copy the packed vector to the device
///     nvbio::PackedVector<device_tag,ALPHABET_SIZE> d_dna( h_dna );
/// }
///\endcode
///
/// Next: \subpage hello_dna_2_page

/// \page hello_dna_2_page Hello DNA! - Part 2
///\par
/// This page will teach you to familiarize with NVBIO's notion of \ref strings_page "string sets" and
/// with some basic parallel constructs.
/// Assume you have the string from the previous example, but now want to extract all of its 3-mers,
/// for example to use them in a seed & extend aligner.
/// The collection of all 3-mers can be thought of a set of substrings, or <i>infixes</i> of your original string;
/// NVBIO represents such an object as an InfixSet.
/// Moreover, it provides a function to extract the coordinates of such seeds in <i>parallel</i>.
///
///\code
/// #include <nvbio/basic/packed_vector.h>
/// #include <nvbio/basic/dna.h>
/// #include <nvbio/strings/infix.h>
/// #include <nvbio/strings/seeds.h>
///
/// using namespace nvbio
///
/// void main()
/// {
///     // our hello world ASCII string
///     const char dna_string[] = "ACGTTGCA";
///     const uint32 len = uint32( strlen( dna_string ) );
///
///     // our DNA alphabet size
///     const uint32 ALPHABET_SIZE = 2u;
///
///     // instantiate a packed host vector
///     nvbio::PackedVector<host_tag,ALPHABET_SIZE> h_dna( len );
///
///     // and fill it in with the contents of our original string, converted
///     // to a 2-bit DNA alphabet (i.e. A = 0, C = 1, G = 2, T = 3)
///     nvbio::string_to_dna(
///         dna_string,               // the input ASCII string
///         h_dna.begin() );          // the output iterator
///
///     // copy the packed vector to the device
///     nvbio::PackedVector<device_tag,ALPHABET_SIZE> d_dna( h_dna );
///
///     // prepare a vector to store the coordinates of the resulting infixes
///     nvbio::vector<device_tag,string_infix_coord_type> d_seed_coords;
///
///     const uint32 n_seeds = enumerate_string_seeds(
///         len,                                   // the string length
///         uniform_seeds_functor<>( 3u, 1u ),     // a seeding functor, specifying to extract
///                                                // all 3-mers offset by 1 base each
///         d_seed_coords );                       // the output infix coordinates
///
///     // define an infix-set to represent the resulting infixes
///     typedef nvbio::PackedVector<device_tag,ALPHABET_SIZE>::iterator           packed_iterator_type;
///     typedef nvbio::vector<device_tag,string_infix_coord_type>::const_iterator infix_iterator_type;
///     typedef InfixSet<packed_iterator_type, infix_iterator_type>               infix_set_type;
///
///     infix_set_type d_seeds(
///         n_seeds,                                // the number of infixes in the set
///         d_dna.begin(),                          // the underlying string
///         d_seed_coords.begin() );                // the iterator to the infix coordinates
///
///     ...
///\endcode
///
///\par
/// At this point it would be nice to do something with the string-set we just created.
/// For the sake of the example, we will just print all its strings.
/// Technically, we could just loop through the strings in the set, and print them on the host.
/// However, suppose we want to do it in the native space of the set, i.e. on the device, and
/// suppose we want to do it in parallel: how can we do this?
/// Well, we will do it here using <a href="http://docs.nvidia.com/cuda/thrust/">Thrust</a>, and particularly
/// the <a href="http://thrust.github.io/doc/group__modifying.html">thrust::for_each</a> construct:
///
///\code
///     ...
///
///     thrust::for_each(
///         nvbio::device_tag(),                                 // the execution context
///         thrust::make_counting_iterator(0u),                  // the first element of our loop sequence
///         thrust::make_counting_iterator(0u) + seeds.size(),   // the end element of our loop sequence
///         print_strings<infix_set_type>( seeds ) );            // the loop's body
/// }
///\endcode
///\par
/// Thrust's for_each takes a functor encoding the body of our loop, and applies it to all elements
/// of a sequence. In this case, the sequence is the set of integers [0,n_seeds), and the
/// body of our loop will be the following:
///
///\code
/// template <typename string_set_type>
/// struct print_strings
/// {
///     NVBIO_HOST_DEVICE
///     print_strings(const string_set_type _string_set) : string_set( _string_set ) {}
/// 
///     NVBIO_HOST_DEVICE
///     void operator() (const uint32 i) const
///     {
///         // build an ASCII string for i-th seed
///         char seed[4];
///         nvbio::dna_to_string(
///             string_set[i],                    // the i-th string in the set
///             nvbio::length( string_set[i] ),   // its length
///             seed );                           // the output ASCII string
/// 
///         // and print it...
///         printf("seed[%u] = %s\n", i, seed);
///     }
/// 
///     const string_set_type string_set;
/// };
///\endcode
///
///\par
/// Notice how we marked our print_strings methods with the NVBIO_HOST_DEVICE qualifier: this
/// tells the CUDA compiler that these methods can be compiled both for the host and the device.
/// It is also worth mentioning that if we kept our vectors on the host (i.e. replacing the device_tag
/// specifiers with host_tag), everything would have still run in parallel, except it would have
/// run on the host.

/// \page hello_dna_3_page Hello DNA! - Part 3
///\par
/// This page will make you familiarize with the concept of plain views and how to write
/// templated functors.
/// Suppose that you want to extract each of the 3-mers of a DNA string, encoded as plain
/// integer hashes. In a serial world, you'd just loop through them one by one. In a parallel
/// world, you'd want to use a parallel for_each. The body of the for_each will be a functor
/// class.
///
///\code
/// #include <nvbio/basic/packed_vector.h>
/// #include <nvbio/basic/dna.h>
/// #include <nvbio/basic/primitives.h>
///
/// // define a functor to extract the i-th mer of a string as an integer hash
/// //
/// template <typename string_type, typename output_type>
/// struct hash_functor
/// {
///     hash_functor(string_type _input, output_type _output) : input(_input), output(_output) {}
///
///     // define the functor operator() to extract the i-th 3-mer
///     void operator() (const uint32 i) const
///     {
///         uint32 hash = 0;
///         for (uint32 j = 0; j < 3; ++j)
///             hash |= input[i+j] << (j*2);  // pack the j-th symbol using 2-bits
///
///         output[i] = hash;
///     }
///
///     string_type         input;
///     mutable output_type output;
/// };
///
/// // define a utility function to instantiate the hash functor above, useful to
/// // exploit C++'s Template Argument Deduction and avoid having to always
/// // specify template arguments
/// template <typename string_type, typename output_type>
/// hash_functor<string_type,output_type> make_hash_functor(string_type _input, output_type _output)
/// {
///    return hash_functor<string_type,output_type>( _input, _output );
/// }
///
/// void main()
/// {
///     // our hello world ASCII string
///     const char dna_string[] = "ACGTTGCA";
///     const uint32 len = (uint32)strlen( dna_string );
///
///     // our DNA alphabet size
///     const uint32 ALPHABET_SIZE = 2u;
///
///     // instantiate a packed host vector
///     nvbio::PackedVector<host_tag,ALPHABET_SIZE> h_dna;
///
///     // resize the vector
///     h_dna.resize( len );
///
///     // and fill it in with the contents of our original string, converted
///     // to a 2-bit DNA alphabet (i.e. A = 0, C = 1, G = 2, T = 3)
///     nvbio::string_to_dna(
///         dna_string,               // the input ASCII string
///         h_dna.begin() );          // the output iterator
///
///     // define a vector for storing the output 3-mers
///     nvbio::vector<host_tag,uint32> h_mers( len - 3u );
///
///     // for each i in [0,len-3], extract the i-th 3-mer, in parallel
///     thrust::for_each(
///         host_tag,
///         thrust::make_counting_iterator( 0u ),       // the beginning of the loop sequence
///         thrust::make_counting_iterator( len - 3u ), // the end of the loop sequence
///         make_hash_functor(                          // the for_each "body" functor
///            nvbio::plain_view( h_dna ),
///            nvbio::plain_view( h_mers ) ) );
/// }
///\endcode
